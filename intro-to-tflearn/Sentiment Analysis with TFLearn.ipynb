{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with TFLearn\n",
    "\n",
    "In this notebook, we'll continue Andrew Trask's work by building a network for sentiment analysis on the movie review data. Instead of a network written with Numpy, we'll be using [TFLearn](http://tflearn.org/), a high-level library built on top of TensorFlow. TFLearn makes it simpler to build networks just by defining the layers. It takes care of most of the details for you.\n",
    "\n",
    "We'll start off by importing all the modules we'll need, then load and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Following along with Andrew, our goal here is to convert our reviews into word vectors. The word vectors will have elements representing words in the total vocabulary. If the second position represents the word 'the', for each review we'll count up the number of times 'the' appears in the text and set the second position to that count. I'll show you examples as we build the input data from the reviews data. Check out Andrew's notebook and video for more about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Use the pandas library to read the reviews and postive/negative labels from comma-separated files. The data we're using has already been preprocessed a bit and we know it uses only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  positive\n",
       "1  negative\n",
       "2  positive\n",
       "3  negative\n",
       "4  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high is a cartoon comedy . it ran at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story of a man who has unnatural feelings for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homelessness  or houselessness as george carli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airport    starts as a brand new luxury    pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brilliant over  acting by lesley ann warren . ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  bromwell high is a cartoon comedy . it ran at ...\n",
       "1  story of a man who has unnatural feelings for ...\n",
       "2  homelessness  or houselessness as george carli...\n",
       "3  airport    starts as a brand new luxury    pla...\n",
       "4  brilliant over  acting by lesley ann warren . ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting word frequency\n",
    "\n",
    "To start off we'll need to count how often each word appears in the data. We'll use this count to create a vocabulary we'll use to encode the review data. This resulting count is known as a [bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model). We'll use it to select our vocabulary and build the word vectors. You should have seen how to do this in Andrew's lesson. Try to implement it here using the [Counter class](https://docs.python.org/2/library/collections.html#collections.Counter).\n",
    "\n",
    "> **Exercise:** Create the bag of words from the reviews data and assign it to `total_counts`. The reviews are stores in the `reviews` [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). If you want the reviews as a Numpy array, use `reviews.values`. You can iterate through the rows in the DataFrame with `for idx, row in reviews.iterrows():` ([documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html)). When you break up the reviews into words, use `.split(' ')` instead of `.split()` so your results match ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in data set:  74074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'': 1111930,\n",
       "         'orientals': 6,\n",
       "         'bosox': 2,\n",
       "         'identikit': 2,\n",
       "         'collides': 7,\n",
       "         'amelia': 6,\n",
       "         'chillers': 17,\n",
       "         'youe': 1,\n",
       "         'mimeux': 1,\n",
       "         'proxy': 9,\n",
       "         'fulfilment': 4,\n",
       "         'sidewalk': 57,\n",
       "         'purportedly': 10,\n",
       "         'mostand': 1,\n",
       "         'tasteful': 32,\n",
       "         'meera': 2,\n",
       "         'orenji': 1,\n",
       "         'pacman': 1,\n",
       "         'choise': 1,\n",
       "         'partners': 69,\n",
       "         'etienne': 5,\n",
       "         'volunteering': 6,\n",
       "         'registrar': 3,\n",
       "         'ambitiously': 1,\n",
       "         'didactically': 4,\n",
       "         'takahisa': 1,\n",
       "         'bashevis': 2,\n",
       "         'mismanagement': 2,\n",
       "         'julie': 174,\n",
       "         'tarkosvky': 1,\n",
       "         'zina': 1,\n",
       "         'toturro': 1,\n",
       "         'dumland': 1,\n",
       "         'moocow': 10,\n",
       "         'vanload': 1,\n",
       "         'threesome': 22,\n",
       "         'twitty': 2,\n",
       "         'junebug': 2,\n",
       "         'gimbli': 1,\n",
       "         'wagging': 2,\n",
       "         'birch': 4,\n",
       "         'glances': 25,\n",
       "         'applauded': 27,\n",
       "         'whimsy': 12,\n",
       "         'pirated': 4,\n",
       "         'restarts': 1,\n",
       "         'actioner': 20,\n",
       "         'melanie': 15,\n",
       "         'brunch': 1,\n",
       "         'nough': 1,\n",
       "         'thare': 1,\n",
       "         'warmest': 1,\n",
       "         'dunston': 2,\n",
       "         'guyana': 4,\n",
       "         'taped': 56,\n",
       "         'shaft': 24,\n",
       "         'razor': 65,\n",
       "         'aa': 5,\n",
       "         'dm': 3,\n",
       "         'friedo': 2,\n",
       "         'signifiers': 2,\n",
       "         'tate': 16,\n",
       "         'sifu': 1,\n",
       "         'conspired': 6,\n",
       "         'apparent': 309,\n",
       "         'psm': 3,\n",
       "         'clippie': 1,\n",
       "         'fictionalising': 1,\n",
       "         'lowitz': 1,\n",
       "         'moneymaking': 1,\n",
       "         'reda': 21,\n",
       "         'transmit': 8,\n",
       "         'elevation': 2,\n",
       "         'excused': 20,\n",
       "         'bat': 168,\n",
       "         'teamings': 1,\n",
       "         'predispositions': 1,\n",
       "         'lessor': 2,\n",
       "         'hoists': 2,\n",
       "         'effected': 11,\n",
       "         'newmail': 1,\n",
       "         'eensy': 1,\n",
       "         'utans': 1,\n",
       "         'intermittent': 9,\n",
       "         'blacktop': 2,\n",
       "         'forsyte': 3,\n",
       "         'majel': 1,\n",
       "         'towels': 4,\n",
       "         'twos': 2,\n",
       "         'morgenstern': 1,\n",
       "         'coquettish': 3,\n",
       "         'rocchi': 1,\n",
       "         'raves': 13,\n",
       "         'menstruation': 9,\n",
       "         'keeped': 1,\n",
       "         'royles': 1,\n",
       "         'deoxys': 1,\n",
       "         'rhythmic': 9,\n",
       "         'uncapturable': 1,\n",
       "         'navigation': 2,\n",
       "         'reciprocates': 2,\n",
       "         'vingana': 2,\n",
       "         'repaired': 4,\n",
       "         'jeanson': 3,\n",
       "         'facinating': 2,\n",
       "         'liars': 10,\n",
       "         'gaudini': 1,\n",
       "         'worth': 2278,\n",
       "         'reptilian': 12,\n",
       "         'espoused': 2,\n",
       "         'abhisheh': 1,\n",
       "         'ede': 1,\n",
       "         'rounded': 69,\n",
       "         'beguiling': 7,\n",
       "         'admission': 44,\n",
       "         'rest': 1803,\n",
       "         'pacts': 1,\n",
       "         'tiffani': 4,\n",
       "         'delusive': 1,\n",
       "         'whatchoo': 1,\n",
       "         'deplorably': 2,\n",
       "         'earthquakes': 5,\n",
       "         'ridden': 88,\n",
       "         'kaal': 2,\n",
       "         'triptych': 2,\n",
       "         'sacarstic': 1,\n",
       "         'octress': 1,\n",
       "         'withholding': 6,\n",
       "         'guaranteeing': 2,\n",
       "         'libretto': 4,\n",
       "         'tapestry': 10,\n",
       "         'stapelton': 1,\n",
       "         'pukar': 1,\n",
       "         'humorously': 8,\n",
       "         'scheitz': 1,\n",
       "         'civilisation': 14,\n",
       "         'dorkknobs': 1,\n",
       "         'ronnie': 19,\n",
       "         'gulped': 1,\n",
       "         'gopher': 3,\n",
       "         'reade': 2,\n",
       "         'unmistakably': 9,\n",
       "         'harden': 2,\n",
       "         'mongolian': 1,\n",
       "         'prichard': 2,\n",
       "         'arcand': 4,\n",
       "         'stalled': 5,\n",
       "         'antagonizing': 2,\n",
       "         'partum': 1,\n",
       "         'expressionism': 16,\n",
       "         'koslack': 2,\n",
       "         'discovery': 116,\n",
       "         'noxious': 2,\n",
       "         'emcee': 5,\n",
       "         'inexpertly': 1,\n",
       "         'hefty': 16,\n",
       "         'actally': 1,\n",
       "         'argentin': 1,\n",
       "         'malice': 14,\n",
       "         'prides': 2,\n",
       "         'irc': 1,\n",
       "         'ziman': 1,\n",
       "         'oppinion': 1,\n",
       "         'originate': 5,\n",
       "         'anjelica': 3,\n",
       "         'bitchdom': 1,\n",
       "         'daugther': 1,\n",
       "         'took': 1100,\n",
       "         'emilie': 3,\n",
       "         'belied': 1,\n",
       "         'denholm': 25,\n",
       "         'kinnepolis': 1,\n",
       "         'bernsen': 47,\n",
       "         'roto': 3,\n",
       "         'gault': 1,\n",
       "         'dearies': 1,\n",
       "         'critize': 1,\n",
       "         'kimberely': 1,\n",
       "         'misanthropes': 2,\n",
       "         'deals': 258,\n",
       "         'whyfore': 1,\n",
       "         'direct': 366,\n",
       "         'waldorf': 2,\n",
       "         'unwatchably': 3,\n",
       "         'mcqueen': 64,\n",
       "         'zaz': 5,\n",
       "         'clean': 243,\n",
       "         'dancersand': 1,\n",
       "         'repulsiveness': 3,\n",
       "         'screwiest': 1,\n",
       "         'lessens': 5,\n",
       "         'important': 931,\n",
       "         'doody': 9,\n",
       "         'brogado': 1,\n",
       "         'imaginaire': 1,\n",
       "         'convents': 1,\n",
       "         'cppy': 1,\n",
       "         'nietszche': 2,\n",
       "         'unaired': 4,\n",
       "         'learning': 175,\n",
       "         'amiss': 3,\n",
       "         'irritatingly': 14,\n",
       "         'bakers': 4,\n",
       "         'redstone': 1,\n",
       "         'loire': 2,\n",
       "         'decapitation': 16,\n",
       "         'whey': 1,\n",
       "         'italianness': 1,\n",
       "         'invasion': 91,\n",
       "         'khakkee': 1,\n",
       "         'meance': 1,\n",
       "         'leaving': 481,\n",
       "         'quoting': 30,\n",
       "         'shahids': 2,\n",
       "         'hoodlum': 13,\n",
       "         'dispose': 16,\n",
       "         'censure': 3,\n",
       "         'expressiveness': 2,\n",
       "         'since': 2907,\n",
       "         'librarians': 10,\n",
       "         'filmgoers': 9,\n",
       "         'frothy': 10,\n",
       "         'junkie': 24,\n",
       "         'drew': 245,\n",
       "         'braik': 1,\n",
       "         'irrationality': 2,\n",
       "         'stylisation': 1,\n",
       "         'lyu': 4,\n",
       "         'minerva': 3,\n",
       "         'incurably': 1,\n",
       "         'gaya': 2,\n",
       "         'steadican': 1,\n",
       "         'cabell': 8,\n",
       "         'bloodymonday': 1,\n",
       "         'symphonie': 1,\n",
       "         'lisaraye': 1,\n",
       "         'arclight': 1,\n",
       "         'zaku': 1,\n",
       "         'crappier': 3,\n",
       "         'lecouvreur': 1,\n",
       "         'duffy': 4,\n",
       "         'bubblingly': 1,\n",
       "         'consolidated': 1,\n",
       "         'krishna': 32,\n",
       "         'correctional': 9,\n",
       "         'foleying': 1,\n",
       "         'elbaorating': 1,\n",
       "         'minimal': 119,\n",
       "         'mismatch': 5,\n",
       "         'ojos': 4,\n",
       "         'motions': 52,\n",
       "         'menagerie': 7,\n",
       "         'goering': 1,\n",
       "         'mccain': 4,\n",
       "         'mart': 43,\n",
       "         'wired': 11,\n",
       "         'openminded': 1,\n",
       "         'xenos': 2,\n",
       "         'goldworthy': 1,\n",
       "         'jars': 12,\n",
       "         'coordinator': 5,\n",
       "         'framing': 41,\n",
       "         'criminals': 174,\n",
       "         'raisers': 2,\n",
       "         'toll': 28,\n",
       "         'spurring': 1,\n",
       "         'sort': 1472,\n",
       "         'changin': 1,\n",
       "         'inaugurated': 1,\n",
       "         'insecure': 31,\n",
       "         'bollixed': 1,\n",
       "         'lansky': 1,\n",
       "         'turned': 925,\n",
       "         'mediocreland': 1,\n",
       "         'lensman': 17,\n",
       "         'homogenized': 6,\n",
       "         'reprised': 4,\n",
       "         'somesuch': 1,\n",
       "         'usc': 8,\n",
       "         'relations': 102,\n",
       "         'volvos': 2,\n",
       "         'hdn': 1,\n",
       "         'backgrounds': 101,\n",
       "         'pollinating': 2,\n",
       "         'denies': 14,\n",
       "         'golem': 14,\n",
       "         'nadia': 24,\n",
       "         'holmann': 1,\n",
       "         'supervised': 4,\n",
       "         'improv': 12,\n",
       "         'synching': 2,\n",
       "         'wards': 19,\n",
       "         'twisted': 199,\n",
       "         'louise': 90,\n",
       "         'blazkowicz': 2,\n",
       "         'fc': 5,\n",
       "         'radiate': 3,\n",
       "         'earwax': 1,\n",
       "         'fruition': 15,\n",
       "         'refreshed': 5,\n",
       "         'concerts': 17,\n",
       "         'reformers': 2,\n",
       "         'latke': 1,\n",
       "         'lamest': 20,\n",
       "         'social': 582,\n",
       "         'airphone': 1,\n",
       "         'vous': 4,\n",
       "         'holster': 2,\n",
       "         'grossness': 8,\n",
       "         'xtro': 4,\n",
       "         'barthelmy': 1,\n",
       "         'gianni': 6,\n",
       "         'threesomes': 2,\n",
       "         'tv': 2782,\n",
       "         'reissuing': 1,\n",
       "         'undresses': 6,\n",
       "         'spoilerskhamosh': 1,\n",
       "         'respiration': 1,\n",
       "         'caddy': 3,\n",
       "         'sailors': 35,\n",
       "         'parochialism': 1,\n",
       "         'ogles': 2,\n",
       "         'flourescent': 2,\n",
       "         'droid': 4,\n",
       "         'cologne': 3,\n",
       "         'hyer': 2,\n",
       "         'didgeridoo': 1,\n",
       "         'elaborates': 3,\n",
       "         'carfully': 1,\n",
       "         'showboat': 2,\n",
       "         'contrite': 4,\n",
       "         'scoped': 2,\n",
       "         'reincarnation': 33,\n",
       "         'puzzle': 55,\n",
       "         'researches': 3,\n",
       "         'scully': 17,\n",
       "         'sentinels': 1,\n",
       "         'knob': 5,\n",
       "         'barbed': 13,\n",
       "         'elke': 3,\n",
       "         'dining': 20,\n",
       "         'decayed': 5,\n",
       "         'inquilino': 1,\n",
       "         'photogrsphed': 1,\n",
       "         'shepherds': 4,\n",
       "         'brainwashing': 11,\n",
       "         'refugees': 19,\n",
       "         'rys': 1,\n",
       "         'eroticism': 29,\n",
       "         'esrechowitz': 1,\n",
       "         'takemitsu': 1,\n",
       "         'juniors': 1,\n",
       "         'lena': 99,\n",
       "         'bears': 140,\n",
       "         'bleeder': 1,\n",
       "         'admonition': 1,\n",
       "         'laconian': 1,\n",
       "         'fiction': 476,\n",
       "         'gregory': 79,\n",
       "         'what': 16159,\n",
       "         'hobbyhorse': 1,\n",
       "         'lollobrigida': 13,\n",
       "         'buyer': 10,\n",
       "         'tron': 7,\n",
       "         'sobriety': 3,\n",
       "         'hoked': 1,\n",
       "         'monotheism': 1,\n",
       "         'ranching': 2,\n",
       "         'pranks': 35,\n",
       "         'platitudes': 13,\n",
       "         'azmi': 4,\n",
       "         'flattest': 3,\n",
       "         'hereabouts': 1,\n",
       "         'hilltop': 1,\n",
       "         'pivots': 2,\n",
       "         'battled': 3,\n",
       "         'sold': 162,\n",
       "         'biehn': 16,\n",
       "         'chalky': 1,\n",
       "         'eidos': 3,\n",
       "         'measurement': 1,\n",
       "         'ga': 11,\n",
       "         'rustic': 7,\n",
       "         'ampas': 2,\n",
       "         'universalsoldier': 1,\n",
       "         'sigmund': 6,\n",
       "         'matriarchal': 2,\n",
       "         'maraglia': 1,\n",
       "         'introvert': 8,\n",
       "         'occupants': 14,\n",
       "         'riffles': 1,\n",
       "         'collectibles': 1,\n",
       "         'dramatizations': 1,\n",
       "         'weekdays': 2,\n",
       "         'separable': 1,\n",
       "         'gravelings': 1,\n",
       "         'shrieking': 21,\n",
       "         'schirripa': 1,\n",
       "         'dealings': 17,\n",
       "         'leprous': 2,\n",
       "         'atm': 2,\n",
       "         'pythons': 2,\n",
       "         'toyo': 1,\n",
       "         'relay': 7,\n",
       "         'sarat': 1,\n",
       "         'squirted': 4,\n",
       "         'respectful': 27,\n",
       "         'tribeswomen': 1,\n",
       "         'coupled': 66,\n",
       "         'mehemet': 1,\n",
       "         'meeker': 17,\n",
       "         'nurses': 15,\n",
       "         'gunplay': 12,\n",
       "         'irrationally': 2,\n",
       "         'newton': 21,\n",
       "         'guardsmen': 2,\n",
       "         'tlog': 1,\n",
       "         'inescapeable': 1,\n",
       "         'merest': 1,\n",
       "         'shrew': 9,\n",
       "         'tutee': 1,\n",
       "         'bookish': 9,\n",
       "         'mike': 282,\n",
       "         'nullifies': 1,\n",
       "         'frisco': 3,\n",
       "         'wean': 2,\n",
       "         'covers': 135,\n",
       "         'broadsword': 1,\n",
       "         'manager': 159,\n",
       "         'morphing': 8,\n",
       "         'navy': 162,\n",
       "         'remand': 1,\n",
       "         'hijacking': 11,\n",
       "         'milch': 2,\n",
       "         'uld': 15,\n",
       "         'liebman': 5,\n",
       "         'terrorise': 4,\n",
       "         'amen': 8,\n",
       "         'gci': 2,\n",
       "         'matchsticks': 2,\n",
       "         'crusades': 3,\n",
       "         'worshipful': 1,\n",
       "         'boggles': 21,\n",
       "         'unidimensional': 1,\n",
       "         'browbeating': 2,\n",
       "         'staffed': 1,\n",
       "         'preempt': 1,\n",
       "         'preity': 15,\n",
       "         'hennenlotter': 1,\n",
       "         'hemmerling': 1,\n",
       "         'resonating': 3,\n",
       "         'separates': 16,\n",
       "         'proportionately': 2,\n",
       "         'misinforming': 1,\n",
       "         'occidental': 4,\n",
       "         'exterminating': 4,\n",
       "         'sleeved': 1,\n",
       "         'fobh': 1,\n",
       "         'chocked': 4,\n",
       "         'guises': 4,\n",
       "         'naturalistic': 25,\n",
       "         'unspools': 2,\n",
       "         'throws': 167,\n",
       "         'revolutionairies': 1,\n",
       "         'glasses': 80,\n",
       "         'torso': 24,\n",
       "         'charistmatic': 1,\n",
       "         'colours': 60,\n",
       "         'carlas': 2,\n",
       "         'arc': 64,\n",
       "         'coeds': 5,\n",
       "         'shifted': 13,\n",
       "         'jamie': 128,\n",
       "         'malevolent': 28,\n",
       "         'seas': 27,\n",
       "         'econovan': 1,\n",
       "         'turbans': 3,\n",
       "         'akshaya': 1,\n",
       "         'strikebreakers': 1,\n",
       "         'tat': 13,\n",
       "         'interwoven': 20,\n",
       "         'shannyn': 4,\n",
       "         'swordfish': 4,\n",
       "         'featherweight': 3,\n",
       "         'broaching': 1,\n",
       "         'inferiors': 1,\n",
       "         'props': 105,\n",
       "         'merge': 14,\n",
       "         'pies': 11,\n",
       "         'entrepreneur': 14,\n",
       "         'esamples': 1,\n",
       "         'bohumil': 1,\n",
       "         'dei': 3,\n",
       "         'everingham': 3,\n",
       "         'aristides': 1,\n",
       "         'kont': 1,\n",
       "         'greenland': 2,\n",
       "         'seemd': 1,\n",
       "         'chiller': 28,\n",
       "         'anisio': 6,\n",
       "         'viennese': 11,\n",
       "         'anya': 3,\n",
       "         'triller': 2,\n",
       "         'campers': 30,\n",
       "         'bmovies': 1,\n",
       "         'casablanca': 51,\n",
       "         'persson': 1,\n",
       "         'ghosties': 1,\n",
       "         'lamarre': 1,\n",
       "         'juries': 2,\n",
       "         'gaffney': 2,\n",
       "         'outstripping': 1,\n",
       "         'ripened': 1,\n",
       "         'paternity': 2,\n",
       "         'ration': 3,\n",
       "         'mann': 124,\n",
       "         'aftershock': 1,\n",
       "         'laced': 38,\n",
       "         'pouter': 1,\n",
       "         'jewel': 56,\n",
       "         'revisionism': 8,\n",
       "         'gloaming': 1,\n",
       "         'bowie': 23,\n",
       "         'jewison': 11,\n",
       "         'distracting': 107,\n",
       "         'nadu': 2,\n",
       "         'zwick': 7,\n",
       "         'derrick': 5,\n",
       "         'wynn': 10,\n",
       "         'costarring': 1,\n",
       "         'fanboys': 9,\n",
       "         'hardness': 2,\n",
       "         'exposure': 82,\n",
       "         'extraterrestrials': 2,\n",
       "         'garrett': 14,\n",
       "         'bucco': 1,\n",
       "         'byrds': 2,\n",
       "         'pederast': 1,\n",
       "         'trueheart': 2,\n",
       "         'medioacre': 1,\n",
       "         'cavities': 2,\n",
       "         'journal': 18,\n",
       "         'orbs': 2,\n",
       "         'seagall': 2,\n",
       "         'lemoine': 4,\n",
       "         'ping': 21,\n",
       "         'magnifique': 1,\n",
       "         'hyperbolize': 1,\n",
       "         'vamps': 4,\n",
       "         'implausible': 108,\n",
       "         'contradictorily': 2,\n",
       "         'ghungroo': 2,\n",
       "         'rodent': 10,\n",
       "         'hoola': 1,\n",
       "         'chauvinism': 2,\n",
       "         'motivation': 122,\n",
       "         'paloozas': 1,\n",
       "         'custom': 21,\n",
       "         'whether': 856,\n",
       "         'klaw': 13,\n",
       "         'curative': 1,\n",
       "         'goldmine': 7,\n",
       "         'buzzwords': 1,\n",
       "         'underwear': 61,\n",
       "         'residences': 2,\n",
       "         'pr': 19,\n",
       "         'argument': 118,\n",
       "         'snowy': 37,\n",
       "         'pacierkowski': 1,\n",
       "         'teller': 26,\n",
       "         'marshmorton': 3,\n",
       "         'duplicity': 8,\n",
       "         'feminist': 84,\n",
       "         'undemanding': 21,\n",
       "         'underly': 1,\n",
       "         'donovan': 15,\n",
       "         'moor': 5,\n",
       "         'desando': 1,\n",
       "         'remains': 439,\n",
       "         'martindale': 6,\n",
       "         'emotionally': 241,\n",
       "         'capper': 3,\n",
       "         'dennehy': 10,\n",
       "         'ageless': 6,\n",
       "         'honeymoon': 35,\n",
       "         'overfilled': 1,\n",
       "         'stanwick': 2,\n",
       "         'cleared': 18,\n",
       "         'ized': 3,\n",
       "         'persuades': 21,\n",
       "         'drank': 11,\n",
       "         'braindead': 14,\n",
       "         'leapin': 1,\n",
       "         'eloquently': 10,\n",
       "         'spinster': 24,\n",
       "         'weebl': 1,\n",
       "         'whitlow': 2,\n",
       "         'arab': 61,\n",
       "         'mvovies': 1,\n",
       "         'educates': 3,\n",
       "         'pancreas': 2,\n",
       "         'reaccounting': 1,\n",
       "         'okazaki': 1,\n",
       "         'downriver': 1,\n",
       "         'stanza': 2,\n",
       "         'goebbels': 23,\n",
       "         'backstory': 24,\n",
       "         'urged': 5,\n",
       "         'luftwaffe': 4,\n",
       "         'arg': 2,\n",
       "         'poptart': 1,\n",
       "         'volcanoes': 3,\n",
       "         'mmmmmmm': 1,\n",
       "         'drexel': 1,\n",
       "         'cordaraby': 1,\n",
       "         'gambling': 73,\n",
       "         'kanin': 9,\n",
       "         'marney': 1,\n",
       "         'downwards': 12,\n",
       "         'yolande': 5,\n",
       "         'glossty': 1,\n",
       "         'goosier': 1,\n",
       "         'yas': 2,\n",
       "         'todd': 112,\n",
       "         'routines': 55,\n",
       "         'phh': 1,\n",
       "         'buchinsky': 1,\n",
       "         'ids': 1,\n",
       "         'ursine': 1,\n",
       "         'upending': 1,\n",
       "         'comfortable': 110,\n",
       "         'astrotheology': 1,\n",
       "         'espn': 3,\n",
       "         'peugeot': 1,\n",
       "         'renews': 2,\n",
       "         'fransico': 1,\n",
       "         'nonintentional': 1,\n",
       "         'emails': 8,\n",
       "         'thugees': 3,\n",
       "         'pitting': 10,\n",
       "         'movieeven': 1,\n",
       "         'dish': 40,\n",
       "         'grasping': 12,\n",
       "         'stall': 9,\n",
       "         'satellite': 33,\n",
       "         'licker': 1,\n",
       "         'oaks': 1,\n",
       "         'ancha': 1,\n",
       "         'kostner': 1,\n",
       "         'bemoan': 4,\n",
       "         'dai': 2,\n",
       "         'caliban': 1,\n",
       "         'seamstress': 4,\n",
       "         'reguritated': 1,\n",
       "         'farrakhan': 2,\n",
       "         'thunderstorms': 1,\n",
       "         'nobly': 5,\n",
       "         'fondue': 1,\n",
       "         'porters': 2,\n",
       "         'carvan': 1,\n",
       "         'placeholder': 1,\n",
       "         'giornata': 4,\n",
       "         'moralism': 2,\n",
       "         'erna': 2,\n",
       "         'relocated': 5,\n",
       "         'offensiveness': 3,\n",
       "         'hostages': 22,\n",
       "         'births': 3,\n",
       "         'smetimes': 1,\n",
       "         'throaty': 2,\n",
       "         'marlboro': 1,\n",
       "         'nabs': 1,\n",
       "         'governmentally': 1,\n",
       "         'clint': 110,\n",
       "         'yabba': 1,\n",
       "         'flinging': 1,\n",
       "         'dody': 2,\n",
       "         'subways': 2,\n",
       "         'pickett': 1,\n",
       "         'horsie': 1,\n",
       "         'albany': 3,\n",
       "         'unimpressed': 11,\n",
       "         'cloudkicker': 6,\n",
       "         'seesaw': 2,\n",
       "         'distasteful': 29,\n",
       "         'lupe': 4,\n",
       "         'villified': 1,\n",
       "         'ronin': 9,\n",
       "         'reverbed': 1,\n",
       "         'oblique': 6,\n",
       "         'bhamra': 4,\n",
       "         'dialogue': 1542,\n",
       "         'graduation': 23,\n",
       "         'bering': 1,\n",
       "         'accidently': 6,\n",
       "         'squawks': 1,\n",
       "         'themthe': 1,\n",
       "         'toothpick': 2,\n",
       "         'pap': 17,\n",
       "         'lazarus': 4,\n",
       "         'turturro': 30,\n",
       "         'docudrama': 17,\n",
       "         'rewarded': 49,\n",
       "         'aspiring': 76,\n",
       "         'gruffudd': 4,\n",
       "         'bluegrass': 4,\n",
       "         'davidson': 19,\n",
       "         'ioffer': 1,\n",
       "         'heidi': 10,\n",
       "         'shielded': 2,\n",
       "         'letting': 146,\n",
       "         'acrap': 1,\n",
       "         'filmaking': 4,\n",
       "         'encode': 1,\n",
       "         'sugarcoated': 1,\n",
       "         'deciphering': 2,\n",
       "         'ghetoization': 1,\n",
       "         'turrets': 1,\n",
       "         'cronenberg': 14,\n",
       "         'anorexia': 1,\n",
       "         'spastically': 1,\n",
       "         'revisited': 12,\n",
       "         'fujiko': 6,\n",
       "         'shawnham': 1,\n",
       "         'brettschneider': 9,\n",
       "         'smudge': 4,\n",
       "         'televison': 2,\n",
       "         'drizzling': 1,\n",
       "         'wale': 2,\n",
       "         'lifeforms': 2,\n",
       "         'amok': 35,\n",
       "         'humanitarianism': 1,\n",
       "         'annabeth': 1,\n",
       "         'adams': 98,\n",
       "         'pharaohs': 1,\n",
       "         'gteborg': 1,\n",
       "         'sender': 4,\n",
       "         'ashwar': 5,\n",
       "         'libraries': 3,\n",
       "         'abounds': 10,\n",
       "         'anually': 1,\n",
       "         'quietest': 2,\n",
       "         'practitioner': 8,\n",
       "         'coast': 80,\n",
       "         'cassavettes': 14,\n",
       "         'uproar': 12,\n",
       "         'summerslam': 6,\n",
       "         'naturist': 1,\n",
       "         'vaio': 1,\n",
       "         'virology': 1,\n",
       "         'demigods': 1,\n",
       "         'absalom': 2,\n",
       "         'stinks': 97,\n",
       "         'similalry': 1,\n",
       "         'sympathy': 199,\n",
       "         'experiment': 170,\n",
       "         'tomeihere': 1,\n",
       "         'reitman': 14,\n",
       "         'pierson': 3,\n",
       "         'cite': 9,\n",
       "         'calitri': 4,\n",
       "         'fidgeted': 2,\n",
       "         'cultural': 184,\n",
       "         'ecw': 2,\n",
       "         'genitalia': 14,\n",
       "         'dennis': 176,\n",
       "         'hota': 1,\n",
       "         'overreaching': 1,\n",
       "         'tender': 101,\n",
       "         'regarding': 174,\n",
       "         'lenka': 2,\n",
       "         'slugger': 3,\n",
       "         'babaloo': 4,\n",
       "         'paedophiliac': 1,\n",
       "         'wed': 15,\n",
       "         'huntress': 3,\n",
       "         'buffay': 2,\n",
       "         'homerian': 3,\n",
       "         'breakage': 1,\n",
       "         'vijay': 18,\n",
       "         'necessarily': 180,\n",
       "         'deodato': 9,\n",
       "         'elective': 1,\n",
       "         'manfish': 2,\n",
       "         'zzzzzzzzzzzzz': 1,\n",
       "         'kiran': 1,\n",
       "         'rashomon': 6,\n",
       "         'lobsters': 1,\n",
       "         'protect': 165,\n",
       "         'silhouetted': 5,\n",
       "         'wrench': 12,\n",
       "         'masculinity': 18,\n",
       "         'tsurumi': 1,\n",
       "         'carpets': 3,\n",
       "         'bowled': 6,\n",
       "         'kaliganj': 1,\n",
       "         'ungratifying': 1,\n",
       "         'occurrence': 23,\n",
       "         'moderne': 1,\n",
       "         'transmitted': 15,\n",
       "         'rejects': 51,\n",
       "         'unawkward': 1,\n",
       "         'tosses': 21,\n",
       "         'overtime': 7,\n",
       "         'bursting': 27,\n",
       "         'orc': 2,\n",
       "         'munches': 1,\n",
       "         'derision': 13,\n",
       "         'laugthers': 1,\n",
       "         'hypnotized': 23,\n",
       "         'cem': 1,\n",
       "         'reintegrate': 1,\n",
       "         'zatoichi': 33,\n",
       "         'tommyknockers': 1,\n",
       "         'thiat': 1,\n",
       "         'lookin': 9,\n",
       "         'hauteur': 1,\n",
       "         'contingent': 8,\n",
       "         'selective': 13,\n",
       "         'stevson': 1,\n",
       "         'aznar': 1,\n",
       "         'bearand': 1,\n",
       "         'apharan': 1,\n",
       "         'glows': 14,\n",
       "         'odious': 11,\n",
       "         'shuddered': 4,\n",
       "         'cinerama': 2,\n",
       "         'enough': 3452,\n",
       "         'gravelly': 5,\n",
       "         'young': 3660,\n",
       "         'wich': 9,\n",
       "         'buster': 81,\n",
       "         'hilton': 40,\n",
       "         'whiskeys': 1,\n",
       "         'receding': 4,\n",
       "         'forster': 9,\n",
       "         'nondenominational': 1,\n",
       "         'orbital': 2,\n",
       "         'mod': 11,\n",
       "         'hounslow': 1,\n",
       "         'preening': 4,\n",
       "         'suddenness': 2,\n",
       "         'campmates': 1,\n",
       "         'amicably': 2,\n",
       "         'patterns': 30,\n",
       "         'mosely': 1,\n",
       "         'countrywoman': 1,\n",
       "         'jake': 160,\n",
       "         'easiness': 4,\n",
       "         'grittiness': 5,\n",
       "         'montano': 7,\n",
       "         'ana': 26,\n",
       "         'karens': 1,\n",
       "         'gunghroo': 1,\n",
       "         'yoakam': 6,\n",
       "         'suet': 3,\n",
       "         'doxy': 1,\n",
       "         'hints': 103,\n",
       "         'weta': 1,\n",
       "         'zima': 2,\n",
       "         'saruman': 6,\n",
       "         'flourishing': 6,\n",
       "         'muere': 1,\n",
       "         'daring': 114,\n",
       "         'parlor': 14,\n",
       "         'partido': 1,\n",
       "         'troubadour': 4,\n",
       "         'horshack': 1,\n",
       "         'nutritional': 4,\n",
       "         'prohibition': 15,\n",
       "         'torrent': 15,\n",
       "         'disrobing': 3,\n",
       "         'source': 206,\n",
       "         'sideline': 5,\n",
       "         'omens': 5,\n",
       "         'raciest': 2,\n",
       "         'dubiel': 1,\n",
       "         'intruded': 2,\n",
       "         'misguidedly': 2,\n",
       "         'relocate': 6,\n",
       "         'jezuz': 1,\n",
       "         'maxwells': 1,\n",
       "         'heian': 1,\n",
       "         'quillan': 3,\n",
       "         'bleach': 7,\n",
       "         'museum': 96,\n",
       "         'realm': 73,\n",
       "         'gah': 1,\n",
       "         'ninnies': 1,\n",
       "         'wertmuller': 2,\n",
       "         'negras': 1,\n",
       "         'evaporated': 3,\n",
       "         'escpecially': 1,\n",
       "         'shonky': 4,\n",
       "         'vegan': 2,\n",
       "         'yuma': 19,\n",
       "         'cliffhangin': 1,\n",
       "         'repents': 3,\n",
       "         'preyall': 1,\n",
       "         'austrailian': 2,\n",
       "         'ambersoms': 1,\n",
       "         'tessering': 1,\n",
       "         'undependable': 1,\n",
       "         'proctor': 1,\n",
       "         'burgundians': 5,\n",
       "         'poseidon': 3,\n",
       "         'aito': 5,\n",
       "         'rejoice': 12,\n",
       "         'unbend': 1,\n",
       "         'miserabley': 1,\n",
       "         'lucio': 33,\n",
       "         'gomba': 1,\n",
       "         'wildfell': 3,\n",
       "         'tasmanian': 2,\n",
       "         'flew': 38,\n",
       "         'emile': 11,\n",
       "         'impaling': 4,\n",
       "         'keels': 2,\n",
       "         'superficiality': 14,\n",
       "         'expresion': 1,\n",
       "         'naval': 35,\n",
       "         'spoliers': 1,\n",
       "         'renegade': 25,\n",
       "         'visby': 1,\n",
       "         'commit': 127,\n",
       "         'reassertion': 1,\n",
       "         'makeout': 2,\n",
       "         'auteur': 41,\n",
       "         'workplace': 11,\n",
       "         'casevettes': 1,\n",
       "         'awakening': 53,\n",
       "         'spurs': 2,\n",
       "         'clones': 24,\n",
       "         'feeds': 25,\n",
       "         'dissipating': 2,\n",
       "         'baffles': 12,\n",
       "         'thusly': 2,\n",
       "         'embarrasses': 7,\n",
       "         'cramp': 7,\n",
       "         'reemergence': 2,\n",
       "         'simplistically': 2,\n",
       "         'bartley': 4,\n",
       "         'rammed': 16,\n",
       "         'charted': 4,\n",
       "         'forklifts': 1,\n",
       "         'stroh': 6,\n",
       "         'thorp': 2,\n",
       "         'cranial': 4,\n",
       "         'pimp': 29,\n",
       "         'tacks': 4,\n",
       "         'cellan': 1,\n",
       "         'mallepa': 5,\n",
       "         'misconstrue': 1,\n",
       "         'follow': 787,\n",
       "         'millan': 1,\n",
       "         'adhering': 3,\n",
       "         'gretzky': 1,\n",
       "         'flipped': 16,\n",
       "         'crossroads': 12,\n",
       "         'chutki': 1,\n",
       "         'puuurfect': 1,\n",
       "         'sharers': 1,\n",
       "         'hulchul': 4,\n",
       "         'rhetorically': 2,\n",
       "         'firefall': 1,\n",
       "         'aspires': 13,\n",
       "         'dateing': 1,\n",
       "         'sinews': 1,\n",
       "         'redubbed': 2,\n",
       "         'screenwriting': 8,\n",
       "         'teir': 1,\n",
       "         'unintelligble': 1,\n",
       "         'crop': 32,\n",
       "         'deckchair': 1,\n",
       "         'defying': 16,\n",
       "         'education': 97,\n",
       "         'aftra': 1,\n",
       "         'pinnacles': 2,\n",
       "         'fisted': 26,\n",
       "         'unlisted': 1,\n",
       "         'daniel': 237,\n",
       "         'oakland': 23,\n",
       "         'satiate': 4,\n",
       "         'flexible': 8,\n",
       "         'mayedas': 1,\n",
       "         'stanly': 1,\n",
       "         'headmistress': 12,\n",
       "         'loafer': 1,\n",
       "         'reminiscant': 1,\n",
       "         'poonam': 12,\n",
       "         'servo': 11,\n",
       "         'sublimate': 1,\n",
       "         'suitor': 13,\n",
       "         'cosell': 1,\n",
       "         'obedient': 6,\n",
       "         'gaffari': 2,\n",
       "         'diabolique': 3,\n",
       "         'cookies': 12,\n",
       "         'egotist': 5,\n",
       "         'ragno': 1,\n",
       "         ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "total_counts = Counter()\n",
    "for idx, row in reviews.iterrows():\n",
    "    total_counts.update(row[0].split(' '))# bag of words here\n",
    "\n",
    "    \n",
    "print(\"Total words in data set: \", len(total_counts))\n",
    "total_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the first 10000 most frequent words. As Andrew noted, most of the words in the vocabulary are rarely used so they will have little effect on our predictions. Below, we'll sort `vocab` by the count value and keep the 10000 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'the', '.', 'and', 'a', 'of', 'to', 'is', 'br', 'it', 'in', 'i', 'this', 'that', 's', 'was', 'as', 'for', 'with', 'movie', 'but', 'film', 'you', 'on', 't', 'not', 'he', 'are', 'his', 'have', 'be', 'one', 'all', 'at', 'they', 'by', 'an', 'who', 'so', 'from', 'like', 'there', 'her', 'or', 'just', 'about', 'out', 'if', 'has', 'what', 'some', 'good', 'can', 'more', 'she', 'when', 'very', 'up', 'time', 'no']\n"
     ]
    }
   ],
   "source": [
    "#For total_counbts.get\n",
    "#https://www.tutorialspoint.com/python/dictionary_get.htm\n",
    "    \n",
    "\n",
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:10000]\n",
    "print(vocab[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the last word in our vocabulary? We can use this to judge if 10000 is too few. If the last word is pretty common, we probably need to keep more words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspires :  30\n"
     ]
    }
   ],
   "source": [
    "print(vocab[-1], ': ', total_counts[vocab[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last word in our vocabulary shows up in 30 reviews out of 25000. I think it's fair to say this is a tiny proportion of reviews. We are probably fine with this number of words.\n",
    "\n",
    "**Note:** When you run, you may see a different word from the one shown above, but it will also have the value `30`. That's because there are many words tied for that number of counts, and the `Counter` class does not guarantee which one will be returned in the case of a tie.\n",
    "\n",
    "Now for each review in the data, we'll make a word vector. First we need to make a mapping of word to index, pretty easy to do with a dictionary comprehension.\n",
    "\n",
    "> **Exercise:** Create a dictionary called `word2idx` that maps each word in the vocabulary to an index. The first word in `vocab` has index `0`, the second word has index `1`, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'bible': 3365,\n",
       " 'wicker': 9765,\n",
       " 'number': 601,\n",
       " 'z': 4216,\n",
       " 'research': 2270,\n",
       " 'activities': 4943,\n",
       " 'hugh': 3876,\n",
       " 'inherent': 6317,\n",
       " 'counterparts': 8078,\n",
       " 'deeper': 2721,\n",
       " 'fill': 2202,\n",
       " 'dressing': 4788,\n",
       " 'downside': 9632,\n",
       " 'zombi': 5577,\n",
       " 'farmer': 5465,\n",
       " 'priceless': 4794,\n",
       " 'ossessione': 8467,\n",
       " 'realistic': 804,\n",
       " 'miniseries': 6019,\n",
       " 'animated': 1102,\n",
       " 'bob': 1952,\n",
       " 'fuller': 4944,\n",
       " 'christie': 5779,\n",
       " 'ernie': 7533,\n",
       " 'opens': 1995,\n",
       " 'figures': 2542,\n",
       " 'lose': 1563,\n",
       " 'parker': 2109,\n",
       " 'sensibility': 7184,\n",
       " 'unborn': 9527,\n",
       " 'blockbusters': 7296,\n",
       " 'bless': 8261,\n",
       " 'firmly': 5945,\n",
       " 'sidewalk': 6452,\n",
       " 'supermarket': 8362,\n",
       " 'explore': 3724,\n",
       " 'mess': 922,\n",
       " 'burial': 7675,\n",
       " 'decent': 532,\n",
       " 'un': 2557,\n",
       " 'worthless': 3518,\n",
       " 'association': 8950,\n",
       " 'traffic': 5761,\n",
       " 'mills': 8196,\n",
       " 'snl': 4383,\n",
       " 'screenplays': 8262,\n",
       " 'rebellious': 6678,\n",
       " 'story': 64,\n",
       " 'partners': 5617,\n",
       " 'bonanza': 7455,\n",
       " 'ambitions': 6989,\n",
       " 'ensues': 4716,\n",
       " 'toward': 1829,\n",
       " 'minute': 770,\n",
       " 'fbi': 3057,\n",
       " 'radiation': 7847,\n",
       " 'grabbed': 7079,\n",
       " 'clumsily': 9373,\n",
       " 'hardest': 9269,\n",
       " 'sub': 1465,\n",
       " 'unbelievable': 1278,\n",
       " 'dedication': 8593,\n",
       " 'stalks': 9017,\n",
       " 'billy': 1454,\n",
       " 'happy': 633,\n",
       " 'quickly': 923,\n",
       " 'hartley': 4239,\n",
       " 'genius': 1236,\n",
       " 'slaves': 6613,\n",
       " 'notable': 2840,\n",
       " 'sit': 849,\n",
       " 'sharp': 2396,\n",
       " 'gorilla': 7437,\n",
       " 'chat': 8868,\n",
       " 'station': 1658,\n",
       " 'cultural': 2635,\n",
       " 'rosemary': 5377,\n",
       " 'julie': 2765,\n",
       " 'honestly': 1229,\n",
       " 'treated': 1882,\n",
       " 'stewart': 1202,\n",
       " 'crummy': 9528,\n",
       " 'warmth': 4807,\n",
       " 'esther': 5247,\n",
       " 'changing': 2509,\n",
       " 'decide': 1177,\n",
       " 'kissing': 4960,\n",
       " 'subjected': 5140,\n",
       " 'ann': 1818,\n",
       " 'hour': 523,\n",
       " 'franco': 4343,\n",
       " 'savior': 9953,\n",
       " 'confront': 6207,\n",
       " 'conflict': 1903,\n",
       " 'wb': 9752,\n",
       " 'paperhouse': 9609,\n",
       " 'lindsay': 5344,\n",
       " 'ella': 9124,\n",
       " 'representing': 8363,\n",
       " 'contact': 3090,\n",
       " 'sinks': 8115,\n",
       " 'muriel': 8462,\n",
       " 'spooky': 3565,\n",
       " 'springs': 9402,\n",
       " 'chick': 2184,\n",
       " 'experiments': 4642,\n",
       " 'russell': 2384,\n",
       " 'side': 489,\n",
       " 'made': 92,\n",
       " 'aboard': 8709,\n",
       " 'eve': 3761,\n",
       " 'martino': 7312,\n",
       " 'boundaries': 7462,\n",
       " 'princess': 2486,\n",
       " 'cocaine': 7513,\n",
       " 'overacting': 4764,\n",
       " 'crowds': 9377,\n",
       " 'radar': 9407,\n",
       " 'live': 408,\n",
       " 'rendering': 7613,\n",
       " 'amongst': 2891,\n",
       " 'olympic': 9822,\n",
       " 'baseball': 2324,\n",
       " 'taped': 6525,\n",
       " 'historical': 1352,\n",
       " 'engrossing': 5957,\n",
       " 'gags': 1975,\n",
       " 'bland': 1896,\n",
       " 'troma': 6370,\n",
       " 'tie': 4212,\n",
       " 'endure': 4290,\n",
       " 'collect': 6453,\n",
       " 'window': 2015,\n",
       " 'attitudes': 4640,\n",
       " 'candle': 7384,\n",
       " 'complicated': 2711,\n",
       " 'sad': 605,\n",
       " 'fired': 3375,\n",
       " 'northam': 7015,\n",
       " 'colonial': 9583,\n",
       " 'jumped': 4565,\n",
       " 'tend': 2323,\n",
       " 'reminding': 7660,\n",
       " 'tender': 4221,\n",
       " 'babies': 5255,\n",
       " 'anxious': 6965,\n",
       " 'apparent': 1708,\n",
       " 'trade': 3261,\n",
       " 'bittersweet': 7526,\n",
       " 'intensity': 2982,\n",
       " 'formulaic': 4339,\n",
       " 'masterpiece': 970,\n",
       " 'entertained': 2151,\n",
       " 'traits': 6626,\n",
       " 'cons': 6001,\n",
       " 'quentin': 6420,\n",
       " 'taste': 1268,\n",
       " 'reckless': 8441,\n",
       " 'smell': 7297,\n",
       " 'screened': 7934,\n",
       " 'soon': 505,\n",
       " 'handling': 5317,\n",
       " 'nerves': 6242,\n",
       " 'disregard': 8024,\n",
       " 'co': 981,\n",
       " 'belushi': 4753,\n",
       " 'stark': 5246,\n",
       " 'rohmer': 7195,\n",
       " 'matching': 9439,\n",
       " 'phrases': 9386,\n",
       " 'river': 1813,\n",
       " 'proved': 2068,\n",
       " 'judges': 8601,\n",
       " 'bat': 2835,\n",
       " 'dillon': 8104,\n",
       " 'asking': 2228,\n",
       " 'worried': 3743,\n",
       " 'gable': 6029,\n",
       " 'wondering': 1511,\n",
       " 'wwii': 3006,\n",
       " 'recording': 4819,\n",
       " 'grab': 3954,\n",
       " 'terror': 2489,\n",
       " 'raised': 2817,\n",
       " 'frozen': 7150,\n",
       " 'news': 1616,\n",
       " 'amoral': 8851,\n",
       " 'pilots': 7335,\n",
       " 'lure': 8892,\n",
       " 'staff': 3950,\n",
       " 'galaxy': 6170,\n",
       " 'failure': 2085,\n",
       " 'legends': 5647,\n",
       " 'monster': 905,\n",
       " 'joins': 5234,\n",
       " 'drift': 7786,\n",
       " 'inherited': 9288,\n",
       " 'minor': 1379,\n",
       " 'ah': 3707,\n",
       " 'needs': 727,\n",
       " 'switching': 7824,\n",
       " 'herd': 7627,\n",
       " 'battlestar': 7228,\n",
       " 'devastated': 9823,\n",
       " 'plane': 1655,\n",
       " 'poet': 8011,\n",
       " 'historically': 4778,\n",
       " 'growing': 1766,\n",
       " 'manhattan': 3661,\n",
       " 'seinfeld': 9076,\n",
       " 'boyfriends': 9122,\n",
       " 'fewer': 8677,\n",
       " 'misunderstood': 7053,\n",
       " 'maniac': 4945,\n",
       " 'progressed': 7553,\n",
       " 'cannon': 5239,\n",
       " 'ka': 9891,\n",
       " 'veterans': 7175,\n",
       " 'drug': 1373,\n",
       " 'levels': 2171,\n",
       " 'crack': 4073,\n",
       " 'et': 4177,\n",
       " 'sentenced': 9422,\n",
       " 'jumbo': 9703,\n",
       " 'don': 90,\n",
       " 'spencer': 6353,\n",
       " 'skip': 1736,\n",
       " 'paired': 8533,\n",
       " 'ma': 8105,\n",
       " 'worth': 289,\n",
       " 'arnie': 7941,\n",
       " 'f': 1313,\n",
       " 'schneider': 6671,\n",
       " 'stretched': 4932,\n",
       " 'comparison': 2053,\n",
       " 'rapture': 8694,\n",
       " 'genres': 3861,\n",
       " 'soulless': 9824,\n",
       " 'ensue': 7896,\n",
       " 'eager': 4477,\n",
       " 'ceiling': 8387,\n",
       " 'ali': 8240,\n",
       " 'notion': 4145,\n",
       " 'rounded': 5618,\n",
       " 'passable': 5075,\n",
       " 'ape': 4094,\n",
       " 'rest': 358,\n",
       " 'derived': 8221,\n",
       " 'favor': 2060,\n",
       " 'evidence': 2268,\n",
       " 'queens': 8165,\n",
       " 'complains': 9697,\n",
       " 'von': 2640,\n",
       " 'release': 753,\n",
       " 'cheerful': 7676,\n",
       " 'raging': 7554,\n",
       " 'orchestral': 9716,\n",
       " 'buy': 798,\n",
       " 'willingly': 8424,\n",
       " 'broad': 3812,\n",
       " 'broke': 3071,\n",
       " 'introduced': 1695,\n",
       " 'assumes': 7830,\n",
       " 'tasteful': 9506,\n",
       " 'praise': 2798,\n",
       " 'dad': 1150,\n",
       " 'stairs': 5655,\n",
       " 'entry': 3176,\n",
       " 'ridden': 4702,\n",
       " 'danger': 2332,\n",
       " 'mrs': 1989,\n",
       " 'believes': 2223,\n",
       " 'noise': 3323,\n",
       " 'few': 171,\n",
       " 'angry': 1602,\n",
       " 'fire': 940,\n",
       " 'extraordinary': 2783,\n",
       " 'consciousness': 6725,\n",
       " 'waves': 4509,\n",
       " 'asset': 8139,\n",
       " 'orange': 4848,\n",
       " 'charlton': 5828,\n",
       " 'contribute': 6466,\n",
       " 'technology': 2096,\n",
       " 'somebody': 1762,\n",
       " 'monks': 7766,\n",
       " 'threatening': 3527,\n",
       " 'approach': 1467,\n",
       " 'core': 1996,\n",
       " 'lame': 817,\n",
       " 'han': 7692,\n",
       " 'dreamy': 7111,\n",
       " 'billing': 8116,\n",
       " 'significance': 5073,\n",
       " 'condescending': 9290,\n",
       " 'jo': 7667,\n",
       " 'older': 903,\n",
       " 'sure': 250,\n",
       " 'crypt': 8205,\n",
       " 'mansion': 2947,\n",
       " 'loy': 6291,\n",
       " 'hopkins': 5302,\n",
       " 'killings': 3401,\n",
       " 'ensuing': 9854,\n",
       " 'ealing': 7695,\n",
       " 'rather': 247,\n",
       " 'television': 680,\n",
       " 'some': 50,\n",
       " 'saving': 1877,\n",
       " 'legs': 2957,\n",
       " 'hogan': 8733,\n",
       " 'surviving': 4130,\n",
       " 'linear': 6080,\n",
       " 'ugly': 1531,\n",
       " 'fame': 2212,\n",
       " 'inspirational': 6057,\n",
       " 'creator': 4564,\n",
       " 'shadows': 3762,\n",
       " 'lung': 9178,\n",
       " 'prey': 5161,\n",
       " 'roaring': 9627,\n",
       " 'rice': 7064,\n",
       " 'sticks': 3763,\n",
       " 'crowe': 7914,\n",
       " 'titled': 3680,\n",
       " 'heading': 5549,\n",
       " 'elvis': 3028,\n",
       " 'evokes': 7569,\n",
       " 'guards': 5992,\n",
       " 'farrell': 4663,\n",
       " 'knowing': 1250,\n",
       " 'discovery': 3767,\n",
       " 'controversy': 7030,\n",
       " 'got': 189,\n",
       " 'heroine': 1807,\n",
       " 'anchors': 8314,\n",
       " 'ruth': 3641,\n",
       " 'giving': 728,\n",
       " 'rooted': 9986,\n",
       " 'services': 7215,\n",
       " 'gray': 3646,\n",
       " 'support': 1403,\n",
       " 'spots': 3200,\n",
       " 'homer': 4202,\n",
       " 'parrot': 7242,\n",
       " 'ancient': 2186,\n",
       " 'likable': 1429,\n",
       " 'rich': 997,\n",
       " 'pops': 4682,\n",
       " 'con': 2673,\n",
       " 'etc': 515,\n",
       " 'aztec': 8919,\n",
       " 'paragraph': 8117,\n",
       " 'rex': 3469,\n",
       " 'breaking': 2203,\n",
       " 'cards': 4305,\n",
       " 'offbeat': 6334,\n",
       " 'discover': 1947,\n",
       " 'greedy': 4580,\n",
       " 'messing': 6475,\n",
       " 'resemblance': 4023,\n",
       " 'ichi': 9856,\n",
       " 'took': 553,\n",
       " 'eggs': 9584,\n",
       " 'duryea': 8989,\n",
       " 'rubbish': 1883,\n",
       " 'yarn': 8386,\n",
       " 'kinky': 9220,\n",
       " 'hoping': 1358,\n",
       " 'fiery': 8294,\n",
       " 'ricky': 6536,\n",
       " 'project': 1149,\n",
       " 'passenger': 8917,\n",
       " 'bernsen': 7374,\n",
       " 'hatred': 3650,\n",
       " 'figured': 2607,\n",
       " 'surrender': 8016,\n",
       " 'bogart': 6676,\n",
       " 'satisfactory': 8788,\n",
       " 'adorable': 4233,\n",
       " 'portuguese': 7515,\n",
       " 'grail': 9507,\n",
       " 'limit': 5706,\n",
       " 'rights': 2637,\n",
       " 'perform': 3092,\n",
       " 'shrill': 8747,\n",
       " 'johnny': 1698,\n",
       " 'blade': 4431,\n",
       " 'leaders': 6000,\n",
       " 'v': 1940,\n",
       " 'whipped': 8678,\n",
       " 'grainy': 5613,\n",
       " 'bachchan': 6603,\n",
       " 'spree': 5818,\n",
       " 'direct': 1480,\n",
       " 'visceral': 8766,\n",
       " 'football': 2281,\n",
       " 'strip': 3202,\n",
       " 'mister': 7935,\n",
       " 'irrelevant': 4849,\n",
       " 'yells': 8214,\n",
       " 'clean': 2106,\n",
       " 'abusive': 4601,\n",
       " 'beat': 1530,\n",
       " 'stimulating': 8996,\n",
       " 'wrestler': 7544,\n",
       " 'jam': 8282,\n",
       " 'overtly': 8931,\n",
       " 'beckinsale': 6795,\n",
       " 'climbing': 7491,\n",
       " 'wears': 2867,\n",
       " 'deserving': 5762,\n",
       " 'developments': 8524,\n",
       " 'farnsworth': 7960,\n",
       " 'laurel': 3658,\n",
       " 'darkest': 9673,\n",
       " 'sized': 6318,\n",
       " 'key': 1296,\n",
       " 'else': 327,\n",
       " 'important': 661,\n",
       " 'wits': 9131,\n",
       " 'kubrick': 3430,\n",
       " 'under': 459,\n",
       " 'was': 15,\n",
       " 'loneliness': 5282,\n",
       " 'diego': 7350,\n",
       " 'val': 7759,\n",
       " 'access': 4558,\n",
       " 'anchorman': 9387,\n",
       " 'lennon': 6214,\n",
       " 'looking': 264,\n",
       " 'ginger': 4033,\n",
       " 'learning': 2744,\n",
       " 'shaped': 5984,\n",
       " 'begs': 7048,\n",
       " 'elevate': 9219,\n",
       " 'valerie': 8713,\n",
       " 've': 140,\n",
       " 'shortly': 3634,\n",
       " 'moron': 6519,\n",
       " 'lifted': 5568,\n",
       " 'cousin': 3147,\n",
       " 'dudley': 5806,\n",
       " 'motif': 9847,\n",
       " 'bravo': 6061,\n",
       " 'reported': 8132,\n",
       " 'magical': 2510,\n",
       " 'moving': 714,\n",
       " 'york': 750,\n",
       " 'gory': 2172,\n",
       " 'player': 1752,\n",
       " 'remain': 2381,\n",
       " 'doll': 4131,\n",
       " 'spock': 4548,\n",
       " 'everywhere': 2561,\n",
       " 'string': 3556,\n",
       " 'artwork': 6007,\n",
       " 'reno': 8284,\n",
       " 'loyalty': 5091,\n",
       " 'wake': 3255,\n",
       " 'second': 331,\n",
       " 'gain': 3206,\n",
       " 'aesthetic': 7669,\n",
       " 'understand': 388,\n",
       " 'leaving': 1179,\n",
       " 'miracles': 9380,\n",
       " 'ok': 597,\n",
       " 'suspenseful': 2539,\n",
       " 'necessity': 7251,\n",
       " 'cocky': 9195,\n",
       " 'clock': 4395,\n",
       " 'shelley': 4448,\n",
       " 'accuracy': 5021,\n",
       " 'aim': 5460,\n",
       " 'bruno': 6280,\n",
       " 'anticipation': 5491,\n",
       " 'crook': 9388,\n",
       " 'walter': 2272,\n",
       " 'redford': 7661,\n",
       " 'formed': 5861,\n",
       " 'satisfy': 4773,\n",
       " 'helpful': 5912,\n",
       " 'embarrassing': 2242,\n",
       " 'illustrate': 8787,\n",
       " 'unanswered': 7000,\n",
       " 'nude': 2483,\n",
       " 'preston': 5063,\n",
       " 'timon': 4497,\n",
       " 'criticism': 2784,\n",
       " 'tackle': 8118,\n",
       " 'stomach': 2851,\n",
       " 'hidden': 1574,\n",
       " 'pin': 4940,\n",
       " 'noises': 5195,\n",
       " 'crazy': 901,\n",
       " 'considerably': 5677,\n",
       " 'boost': 8777,\n",
       " 'blows': 3609,\n",
       " 'flop': 4006,\n",
       " 'positively': 5384,\n",
       " 'successful': 1089,\n",
       " 'escapes': 2906,\n",
       " 'punch': 2781,\n",
       " 'specially': 4843,\n",
       " 'saw': 217,\n",
       " 'backwards': 5739,\n",
       " 'drew': 2093,\n",
       " 'opposed': 3626,\n",
       " 'fought': 5040,\n",
       " 'puppet': 5029,\n",
       " 'reed': 2904,\n",
       " 'obviously': 531,\n",
       " 'describes': 4206,\n",
       " 'weight': 3310,\n",
       " 'shoot': 1220,\n",
       " 'roy': 2225,\n",
       " 'smart': 1359,\n",
       " 'spoofs': 8154,\n",
       " 'town': 488,\n",
       " 'doses': 8853,\n",
       " 'popped': 7313,\n",
       " 'yourselves': 9767,\n",
       " 'contributed': 6715,\n",
       " 'additionally': 6981,\n",
       " 'destiny': 4112,\n",
       " 'impossible': 1145,\n",
       " 'champion': 5675,\n",
       " 'spells': 8635,\n",
       " 'irene': 6294,\n",
       " 'pictures': 1230,\n",
       " 'gate': 5635,\n",
       " 'hudson': 3241,\n",
       " 'testing': 7580,\n",
       " 'included': 1911,\n",
       " 'directorial': 3647,\n",
       " 'filmmakers': 1025,\n",
       " 'flashbacks': 2132,\n",
       " 'ran': 2140,\n",
       " 'attend': 4946,\n",
       " 'dramas': 3251,\n",
       " 'korea': 6618,\n",
       " 'conduct': 9251,\n",
       " 'gladly': 9850,\n",
       " 'encountered': 6813,\n",
       " 'atlantis': 3923,\n",
       " 'marines': 8371,\n",
       " 'hitch': 9790,\n",
       " 'real': 147,\n",
       " 'elected': 8166,\n",
       " 'fassbinder': 6590,\n",
       " 'othello': 4745,\n",
       " 'anita': 7323,\n",
       " 'stoltz': 9240,\n",
       " 'average': 834,\n",
       " 'longer': 1185,\n",
       " 'effective': 1109,\n",
       " 'discovering': 5271,\n",
       " 'bombing': 9024,\n",
       " 'yokai': 6264,\n",
       " 'sabu': 8656,\n",
       " 'rival': 2943,\n",
       " 'premiere': 5182,\n",
       " 'peter': 791,\n",
       " 'points': 746,\n",
       " 'voting': 9610,\n",
       " 'sealed': 9585,\n",
       " 'minimal': 3687,\n",
       " 'epic': 1676,\n",
       " 'sore': 8698,\n",
       " 'burning': 3183,\n",
       " 'scratching': 7968,\n",
       " 'kong': 1923,\n",
       " 'violence': 557,\n",
       " 'nyc': 4782,\n",
       " 'lifestyle': 4113,\n",
       " 'bubble': 6297,\n",
       " 'buffalo': 4992,\n",
       " 'females': 5189,\n",
       " 'regards': 6030,\n",
       " 'elm': 4869,\n",
       " 'climate': 8909,\n",
       " 'behold': 5507,\n",
       " 'pro': 3232,\n",
       " 'messy': 5836,\n",
       " 'scientific': 3704,\n",
       " 'disguised': 6116,\n",
       " 'mart': 7820,\n",
       " 'coolest': 7764,\n",
       " 'theo': 8870,\n",
       " 'makers': 1155,\n",
       " 'tight': 2670,\n",
       " 'driving': 1926,\n",
       " 'ocean': 4147,\n",
       " 'dawson': 3439,\n",
       " 'shameful': 7815,\n",
       " 'cheech': 7865,\n",
       " 'principle': 6326,\n",
       " 'stretches': 9073,\n",
       " 'roots': 5004,\n",
       " 'criminals': 2766,\n",
       " 'unit': 4676,\n",
       " 'substance': 2294,\n",
       " 'debt': 6488,\n",
       " 'everyone': 296,\n",
       " 'hara': 5630,\n",
       " 'susan': 2615,\n",
       " 'myth': 5926,\n",
       " 'visual': 1090,\n",
       " 'difficult': 862,\n",
       " 'sort': 429,\n",
       " 'predict': 5636,\n",
       " 'sake': 2089,\n",
       " 'disappearing': 9301,\n",
       " 'wright': 7050,\n",
       " 'hall': 2284,\n",
       " 'theaters': 2216,\n",
       " 'cassel': 9896,\n",
       " 'hostage': 7361,\n",
       " 'stunt': 3335,\n",
       " 'able': 494,\n",
       " 'anyways': 3834,\n",
       " 'silent': 1265,\n",
       " 'homicidal': 7332,\n",
       " 'insecure': 9700,\n",
       " 'hands': 938,\n",
       " 'teachers': 5236,\n",
       " 'sensible': 6359,\n",
       " 'dogs': 2472,\n",
       " 'rating': 662,\n",
       " 'pitched': 7915,\n",
       " 'temper': 7779,\n",
       " 'dry': 2210,\n",
       " 'arrives': 2926,\n",
       " 'shifting': 8696,\n",
       " 'reputation': 2545,\n",
       " 'dutch': 4122,\n",
       " 'smallest': 9897,\n",
       " 'fake': 1191,\n",
       " 'reviews': 838,\n",
       " 'donna': 3792,\n",
       " 'regret': 2569,\n",
       " 'kung': 2107,\n",
       " 'feelings': 1398,\n",
       " 'whip': 7995,\n",
       " 'model': 2123,\n",
       " 'relations': 4183,\n",
       " 'hang': 3212,\n",
       " 'confuse': 7983,\n",
       " 'cedric': 7521,\n",
       " 'backgrounds': 4220,\n",
       " 'loren': 7202,\n",
       " 'span': 6246,\n",
       " 'rated': 1125,\n",
       " 'marion': 4779,\n",
       " 'seem': 307,\n",
       " 'intriguing': 1748,\n",
       " 'machine': 1645,\n",
       " 'basically': 678,\n",
       " 'bulk': 6072,\n",
       " 'present': 962,\n",
       " 'repressed': 6270,\n",
       " 'bias': 7413,\n",
       " 'length': 1599,\n",
       " 'hysterically': 7252,\n",
       " 'vengeful': 9355,\n",
       " 'replay': 9414,\n",
       " 'crouse': 9255,\n",
       " 'contrast': 2261,\n",
       " 'expectations': 1371,\n",
       " 'godzilla': 4114,\n",
       " 'intentionally': 4641,\n",
       " 'mom': 1483,\n",
       " 'twisted': 2468,\n",
       " 'louise': 4608,\n",
       " 'deliciously': 6863,\n",
       " 'chan': 2412,\n",
       " 'reunite': 7398,\n",
       " 'sloane': 8761,\n",
       " 'computers': 5787,\n",
       " 'pot': 4267,\n",
       " 'ordered': 5179,\n",
       " 'stupid': 373,\n",
       " 'boot': 4425,\n",
       " 'damsel': 8167,\n",
       " 'laugh': 457,\n",
       " 'ride': 1333,\n",
       " 'copied': 6489,\n",
       " 'gloria': 6978,\n",
       " 'leg': 3880,\n",
       " 'drifter': 9434,\n",
       " 'proof': 3129,\n",
       " 'viewing': 812,\n",
       " 'glory': 3142,\n",
       " 'woods': 1378,\n",
       " 'estate': 3464,\n",
       " 'weak': 800,\n",
       " 'dracula': 3683,\n",
       " 'drain': 8210,\n",
       " 'juliette': 6550,\n",
       " 'portrayal': 1120,\n",
       " 'following': 1026,\n",
       " 'stature': 9110,\n",
       " 'voted': 5804,\n",
       " 'pick': 1237,\n",
       " 'boarding': 9770,\n",
       " 'discussion': 3721,\n",
       " 'across': 627,\n",
       " 'next': 371,\n",
       " 'geeky': 9768,\n",
       " 'situations': 1163,\n",
       " 'frankie': 4612,\n",
       " 'choreographer': 9125,\n",
       " 'ties': 4133,\n",
       " 'dread': 6194,\n",
       " 'social': 1007,\n",
       " 'potent': 8565,\n",
       " 'shaq': 9688,\n",
       " 'cunning': 8325,\n",
       " 'thirteen': 9825,\n",
       " 'falling': 1430,\n",
       " 'constraints': 7812,\n",
       " 'composed': 3910,\n",
       " 'desires': 5165,\n",
       " 'method': 4163,\n",
       " 'cents': 6159,\n",
       " 'marisa': 7305,\n",
       " 'bruce': 1405,\n",
       " 'recover': 7628,\n",
       " 'silly': 695,\n",
       " 'daughter': 539,\n",
       " 'maid': 4886,\n",
       " 'faye': 7728,\n",
       " 'maniacal': 9859,\n",
       " 'tv': 243,\n",
       " 'folk': 3776,\n",
       " 'related': 2441,\n",
       " 'wray': 9809,\n",
       " 'latino': 8246,\n",
       " 'different': 272,\n",
       " 'kinski': 7805,\n",
       " 'accepts': 5370,\n",
       " 'lens': 7186,\n",
       " 'mourning': 9396,\n",
       " 'irs': 9858,\n",
       " 'rea': 6716,\n",
       " 'elephants': 8131,\n",
       " 'diamond': 3535,\n",
       " 'hayden': 9724,\n",
       " 'warehouse': 7729,\n",
       " 'title': 422,\n",
       " 'take': 192,\n",
       " 'thomas': 2033,\n",
       " 'mafia': 3427,\n",
       " 'bug': 3700,\n",
       " 'sinister': 2912,\n",
       " 'whom': 915,\n",
       " 'lion': 2866,\n",
       " 'exceptional': 3132,\n",
       " 'batman': 1291,\n",
       " 'coburn': 7253,\n",
       " 'compare': 1639,\n",
       " 'clooney': 6650,\n",
       " 'denver': 8951,\n",
       " 'junk': 2559,\n",
       " 'introduces': 4291,\n",
       " 'scattered': 8667,\n",
       " 'battlefield': 7890,\n",
       " 'apartheid': 8293,\n",
       " 'sing': 1919,\n",
       " 'tended': 8091,\n",
       " 'puzzle': 6610,\n",
       " 'wolf': 3670,\n",
       " 'closer': 2403,\n",
       " 'term': 2850,\n",
       " 'guests': 5497,\n",
       " 'slap': 3615,\n",
       " 'battles': 3336,\n",
       " 'crossed': 7029,\n",
       " 'ruining': 7023,\n",
       " 'experiences': 2465,\n",
       " 'geek': 7039,\n",
       " 'perverted': 7666,\n",
       " 'kidnapping': 6508,\n",
       " 'northern': 5881,\n",
       " 'phil': 5088,\n",
       " 'spielberg': 3038,\n",
       " 'blaxploitation': 9893,\n",
       " 'mirror': 2827,\n",
       " 'mexico': 2628,\n",
       " 'eat': 1884,\n",
       " 'fail': 1831,\n",
       " 'corporation': 6097,\n",
       " 'featured': 2524,\n",
       " 'razor': 5853,\n",
       " 'addition': 1554,\n",
       " 'cameras': 3906,\n",
       " 'sgt': 6277,\n",
       " 'hoffman': 2592,\n",
       " 'gentle': 3790,\n",
       " 'bears': 3245,\n",
       " 'apprentice': 9212,\n",
       " 'fifty': 5203,\n",
       " 'explodes': 6767,\n",
       " 'agatha': 8725,\n",
       " 'williams': 1567,\n",
       " 'rapid': 6922,\n",
       " 'universe': 2491,\n",
       " 'tail': 5474,\n",
       " 'reviewing': 6460,\n",
       " 'corbin': 8554,\n",
       " 'fiction': 1187,\n",
       " 'gregory': 5097,\n",
       " 'assure': 7430,\n",
       " 'lester': 5456,\n",
       " 'what': 49,\n",
       " 'turgid': 9522,\n",
       " 'tall': 3662,\n",
       " 'chose': 2440,\n",
       " 'jealousy': 6474,\n",
       " 'photographer': 3722,\n",
       " 'domino': 4333,\n",
       " 'suit': 1701,\n",
       " 'lumet': 4263,\n",
       " 'skull': 5174,\n",
       " 'carry': 1633,\n",
       " 'surprisingly': 1207,\n",
       " 'adultery': 8388,\n",
       " 'occasions': 5335,\n",
       " 'mainly': 1401,\n",
       " 'il': 8815,\n",
       " 'hood': 2927,\n",
       " 'mind': 328,\n",
       " 'neil': 3356,\n",
       " 'sandler': 2769,\n",
       " 'presented': 1331,\n",
       " 'involvement': 3841,\n",
       " 'entirety': 6203,\n",
       " 'imaginary': 7217,\n",
       " 'neo': 3883,\n",
       " 'accent': 1167,\n",
       " 'unoriginal': 4936,\n",
       " 'blockbuster': 2609,\n",
       " 'steals': 2351,\n",
       " 'jolie': 6683,\n",
       " 'involves': 2264,\n",
       " 'programming': 8092,\n",
       " 'words': 698,\n",
       " 'sold': 2914,\n",
       " 'forrest': 7951,\n",
       " 'forgiven': 5936,\n",
       " 'chevy': 8334,\n",
       " 'day': 246,\n",
       " 'skill': 2691,\n",
       " 'stiles': 7074,\n",
       " 'fields': 5105,\n",
       " 'pervert': 8197,\n",
       " 'disliked': 5141,\n",
       " 'threads': 8594,\n",
       " 'gardens': 9270,\n",
       " 'owning': 9860,\n",
       " 'vicious': 3768,\n",
       " 'fighters': 8335,\n",
       " 'zone': 3162,\n",
       " 'bosses': 7090,\n",
       " 'concepts': 5839,\n",
       " 'thus': 1326,\n",
       " 'disasters': 8845,\n",
       " 'sleep': 1641,\n",
       " 'virgin': 3123,\n",
       " 'absurd': 1722,\n",
       " 'provoking': 2864,\n",
       " 'howard': 1987,\n",
       " 'detailed': 4002,\n",
       " 'drum': 8025,\n",
       " 'overweight': 9826,\n",
       " 'strong': 554,\n",
       " 'love': 116,\n",
       " 'al': 1451,\n",
       " 'unconventional': 7693,\n",
       " 'came': 380,\n",
       " 'blonde': 1924,\n",
       " 'stoned': 7982,\n",
       " 'relating': 7117,\n",
       " 'heston': 3325,\n",
       " 'contemplate': 9152,\n",
       " 'walking': 1264,\n",
       " 'holland': 8790,\n",
       " 'overacts': 9294,\n",
       " 'workers': 2884,\n",
       " 'quietly': 5283,\n",
       " 'wound': 4468,\n",
       " 'agents': 4489,\n",
       " 'secluded': 9878,\n",
       " 'mode': 5331,\n",
       " 'credits': 879,\n",
       " 'perverse': 8285,\n",
       " 'gun': 1031,\n",
       " 'pants': 4482,\n",
       " 'elite': 5713,\n",
       " 'inheritance': 9653,\n",
       " 'elements': 777,\n",
       " 'tears': 1650,\n",
       " 'robbing': 8525,\n",
       " 'grinch': 4164,\n",
       " 'novelist': 7463,\n",
       " 'parks': 8266,\n",
       " 'rosario': 6907,\n",
       " 'coupled': 5788,\n",
       " 'hunters': 4643,\n",
       " 'erika': 6365,\n",
       " 'planted': 9218,\n",
       " 'generate': 7075,\n",
       " 'chris': 1308,\n",
       " 'create': 969,\n",
       " 'precise': 7187,\n",
       " 'approaching': 6319,\n",
       " 'wow': 1284,\n",
       " 'technique': 3095,\n",
       " 'wu': 7961,\n",
       " 'pig': 4204,\n",
       " 'affects': 6127,\n",
       " 'contained': 3857,\n",
       " 'mother': 418,\n",
       " 'mood': 1282,\n",
       " 'strict': 6758,\n",
       " 'moe': 5897,\n",
       " 'charge': 2842,\n",
       " 'my': 61,\n",
       " 'statue': 6020,\n",
       " 'please': 580,\n",
       " 'date': 1277,\n",
       " 'misfire': 9672,\n",
       " 'dime': 9174,\n",
       " 'build': 1677,\n",
       " 'michelle': 2799,\n",
       " 'parking': 6927,\n",
       " 'cillian': 8813,\n",
       " 'weaknesses': 5532,\n",
       " 'leading': 954,\n",
       " 'motivation': 3620,\n",
       " 'charisma': 3305,\n",
       " 'mike': 1846,\n",
       " 'dream': 892,\n",
       " 'legend': 1754,\n",
       " 'suitable': 4486,\n",
       " 'had': 69,\n",
       " 'minded': 2928,\n",
       " 'ambition': 5786,\n",
       " 'heroic': 3810,\n",
       " 'knocked': 5272,\n",
       " 'covers': 3342,\n",
       " 'spring': 3562,\n",
       " 'suggesting': 6820,\n",
       " 'otherwise': 880,\n",
       " 'countries': 3083,\n",
       " 'greed': 4789,\n",
       " 'peck': 5445,\n",
       " 'manager': 2963,\n",
       " 'documented': 9497,\n",
       " 'im': 3795,\n",
       " 'zombie': 819,\n",
       " 'carface': 9019,\n",
       " 'mountains': 3939,\n",
       " 'kareena': 8089,\n",
       " 'slide': 6216,\n",
       " 'failing': 3705,\n",
       " 'izzard': 8748,\n",
       " 'selling': 3445,\n",
       " 'chainsaw': 5419,\n",
       " 'winchester': 5751,\n",
       " 'rage': 3917,\n",
       " 'vice': 4609,\n",
       " 'showcase': 4618,\n",
       " 'connection': 2006,\n",
       " 'feared': 8997,\n",
       " 'rko': 8720,\n",
       " 'animals': 1350,\n",
       " 'qualifies': 8140,\n",
       " 'fairy': 2336,\n",
       " 'kinnear': 6217,\n",
       " 'character': 105,\n",
       " 'entrance': 7188,\n",
       " 'reid': 4785,\n",
       " 'nobody': 1238,\n",
       " 'unforgivable': 9773,\n",
       " 'sr': 9462,\n",
       " 'clan': 5637,\n",
       " 'spectrum': 9492,\n",
       " 'gadget': 3937,\n",
       " 'joel': 5030,\n",
       " 'unpredictable': 4995,\n",
       " 'growth': 6073,\n",
       " 'qualities': 2391,\n",
       " 'godard': 7062,\n",
       " 'owns': 6324,\n",
       " 'harlem': 9028,\n",
       " 'front': 991,\n",
       " 'wanted': 466,\n",
       " 'travolta': 7938,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "word2idx = {}\n",
    "for word in vocab:\n",
    "    word2idx[word] = idx    \n",
    "    idx += 1\n",
    "    #print (word,idx)\n",
    "word2idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to vector function\n",
    "\n",
    "Now we can write a function that converts a some text to a word vector. The function will take a string of words as input and return a vector with the words counted up. Here's the general algorithm to do this:\n",
    "\n",
    "* Initialize the word vector with [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html), it should be the length of the vocabulary.\n",
    "* Split the input string of text into a list of words with `.split(' ')`. Again, if you call `.split()` instead, you'll get slightly different results than what we show here.\n",
    "* For each word in that list, increment the element in the index associated with that word, which you get from `word2idx`.\n",
    "\n",
    "**Note:** Since all words aren't in the `vocab` dictionary, you'll get a key error if you run into one of those words. You can use the `.get` method of the `word2idx` dictionary to specify a default returned value when you make a key error. For example, `word2idx.get(word, None)` returns `None` if `word` doesn't exist in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    word_vec = np.zeros (len(vocab))\n",
    "    \n",
    "    for word in text.split(' '):\n",
    "        if word in word2idx:\n",
    "            word_vec[word2idx[word]] += 1\n",
    "    return word_vec\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do this right, the following code should return\n",
    "\n",
    "```\n",
    "text_to_vector('The tea is for a party to celebrate '\n",
    "               'the movie so she has no time for a cake')[:65]\n",
    "                   \n",
    "array([0, 1, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
    "```       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  2.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  2.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector('The tea is for a party to celebrate '\n",
    "               'the movie so she has no time for a cake')[:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run through our entire review data set and convert each review to a word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = np.zeros((len(reviews), len(vocab)), dtype=np.int_)\n",
    "for ii, (_, text) in enumerate(reviews.iterrows()):\n",
    "    word_vectors[ii] = text_to_vector(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18,   9,  27,   1,   4,   4,   6,   4,   0,   2,   2,   5,   0,\n",
       "          4,   1,   0,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  5,   4,   8,   1,   7,   3,   1,   2,   0,   4,   0,   0,   0,\n",
       "          1,   2,   0,   0,   1,   3,   0,   0,   0,   1],\n",
       "       [ 78,  24,  12,   4,  17,   5,  20,   2,   8,   8,   2,   1,   1,\n",
       "          2,   8,   0,   5,   5,   4,   0,   2,   1,   4],\n",
       "       [167,  53,  23,   0,  22,  23,  13,  14,   8,  10,   8,  12,   9,\n",
       "          4,  11,   2,  11,   5,  11,   0,   5,   3,   0],\n",
       "       [ 19,  10,  11,   4,   6,   2,   2,   5,   0,   1,   2,   3,   1,\n",
       "          0,   0,   0,   3,   1,   0,   1,   0,   0,   0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the first 5 word vectors\n",
    "word_vectors[:5, :23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test sets\n",
    "\n",
    "Now that we have the word_vectors, we're ready to split our data into train, validation, and test sets. Remember that we train on the train data, use the validation data to set the hyperparameters, and at the very end measure the network performance on the test data. Here we're using the function `to_categorical` from TFLearn to reshape the target data so that we'll have two output units and can classify with a softmax activation function. We actually won't be creating the validation set here, TFLearn will do that for us later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = (labels=='positive').astype(np.int_)\n",
    "records = len(labels)\n",
    "\n",
    "shuffle = np.arange(records)\n",
    "np.random.shuffle(shuffle)\n",
    "test_fraction = 0.9\n",
    "\n",
    "train_split, test_split = shuffle[:int(records*test_fraction)], shuffle[int(records*test_fraction):]\n",
    "trainX, trainY = word_vectors[train_split,:], to_categorical(Y.values[train_split], 2)\n",
    "testX, testY = word_vectors[test_split,:], to_categorical(Y.values[test_split], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "[TFLearn](http://tflearn.org/) lets you build the network by [defining the layers](http://tflearn.org/layers/core/). \n",
    "\n",
    "### Input layer\n",
    "\n",
    "For the input layer, you just need to tell it how many units you have. For example, \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 100])\n",
    "```\n",
    "\n",
    "would create a network with 100 input units. The first element in the list, `None` in this case, sets the batch size. Setting it to `None` here leaves it at the default batch size.\n",
    "\n",
    "The number of inputs to your network needs to match the size of your data. For this example, we're using 10000 element long vectors to encode our input data, so we need 10000 input units.\n",
    "\n",
    "\n",
    "### Adding layers\n",
    "\n",
    "To add new hidden layers, you use \n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, n_units, activation='ReLU')\n",
    "```\n",
    "\n",
    "This adds a fully connected layer where every unit in the previous layer is connected to every unit in this layer. The first argument `net` is the network you created in the `tflearn.input_data` call. It's telling the network to use the output of the previous layer as the input to this layer. You can set the number of units in the layer with `n_units`, and set the activation function with the `activation` keyword. You can keep adding layers to your network by repeated calling `net = tflearn.fully_connected(net, n_units)`.\n",
    "\n",
    "### Output layer\n",
    "\n",
    "The last layer you add is used as the output layer. Therefore, you need to set the number of units to match the target data. In this case we are predicting two classes, positive or negative sentiment. You also need to set the activation function so it's appropriate for your model. Again, we're trying to predict if some input data belongs to one of two classes, so we should use softmax.\n",
    "\n",
    "```\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "```\n",
    "\n",
    "### Training\n",
    "To set how you train the network, use \n",
    "\n",
    "```\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "Again, this is passing in the network you've been building. The keywords: \n",
    "\n",
    "* `optimizer` sets the training method, here stochastic gradient descent\n",
    "* `learning_rate` is the learning rate\n",
    "* `loss` determines how the network error is calculated. In this example, with the categorical cross-entropy.\n",
    "\n",
    "Finally you put all this together to create the model with `tflearn.DNN(net)`. So it ends up looking something like \n",
    "\n",
    "```\n",
    "net = tflearn.input_data([None, 10])                          # Input\n",
    "net = tflearn.fully_connected(net, 5, activation='ReLU')      # Hidden\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(net)\n",
    "```\n",
    "\n",
    "> **Exercise:** Below in the `build_model()` function, you'll put together the network using TFLearn. You get to choose how many layers to use, how many hidden units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    net = tflearn.input_data([None, len(vocab)])                          # Input\n",
    "    # Hidden layer(s)\n",
    "    net = tflearn.fully_connected(net, 200, activation='leaky_relu')\n",
    "    net = tflearn.fully_connected(net, 25, activation='leaky_relu')\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "    \n",
    "    #### Your code ####\n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intializing the model\n",
    "\n",
    "Next we need to call the `build_model()` function to actually build the model. In my solution I haven't included any arguments to the function, but you can add arguments so you can change parameters in the model if you want.\n",
    "\n",
    "> **Note:** You might get a bunch of warnings here. TFLearn uses a lot of deprecated code in TensorFlow. Hopefully it gets updated to the new TensorFlow version soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Now that we've constructed the network, saved as the variable `model`, we can fit it to the data. Here we use the `model.fit` method. You pass in the training features `trainX` and the training targets `trainY`. Below I set `validation_set=0.1` which reserves 10% of the data set as the validation set. You can also set the batch size and number of epochs with the `batch_size` and `n_epoch` keywords, respectively. Below is the code to fit our the network to our word vectors.\n",
    "\n",
    "You can rerun `model.fit` to train the network further if you think you can increase the validation accuracy. Remember, all hyperparameter adjustments must be done using the validation set. **Only use the test set after you're completely done training the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15899  | total loss: \u001b[1m\u001b[32m0.18482\u001b[0m\u001b[0m | time: 9.245s\n",
      "| SGD | epoch: 100 | loss: 0.18482 - acc: 0.9187 -- iter: 20224/20250\n",
      "Training Step: 15900  | total loss: \u001b[1m\u001b[32m0.18233\u001b[0m\u001b[0m | time: 10.313s\n",
      "| SGD | epoch: 100 | loss: 0.18233 - acc: 0.9221 | val_loss: 0.39668 - val_acc: 0.8662 -- iter: 20250/20250\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=128, n_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "After you're satisified with your hyperparameters, you can run the network on the test set to measure its performance. Remember, *only do this after finalizing the hyperparameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8552\n"
     ]
    }
   ],
   "source": [
    "predictions = (np.array(model.predict(testX))[:,0] >= 0.5).astype(np.int_)\n",
    "test_accuracy = np.mean(predictions == testY[:,0], axis=0)\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out your own text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function that uses your model to predict sentiment\n",
    "def test_sentence(sentence):\n",
    "    positive_prob = model.predict([text_to_vector(sentence.lower())])[0][1]\n",
    "    print('Sentence: {}'.format(sentence))\n",
    "    print('P(positive) = {:.3f} :'.format(positive_prob), \n",
    "          'Positive' if positive_prob > 0.5 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Moonlight is by far the best movie of 2016.\n",
      "P(positive) = 0.935 : Positive\n",
      "Sentence: The movie is suck\n",
      "P(positive) = 0.613 : Positive\n",
      "Sentence: It's amazing anyone could be talented enough to make something this spectacularly awful\n",
      "P(positive) = 0.013 : Negative\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Moonlight is by far the best movie of 2016.\"\n",
    "test_sentence(sentence)\n",
    "\n",
    "sentence = \"The movie is suck\"\n",
    "test_sentence(sentence)\n",
    "\n",
    "sentence = \"It's amazing anyone could be talented enough to make something this spectacularly awful\"\n",
    "test_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
